import { NextRequest, NextResponse } from "next/server";
import { Mistral } from "@mistralai/mistralai";
import { embedText } from "@/lib/rag/embeddings";
import { createAdminClient } from "@/lib/supabase/admin";
import { TOP_K, SIMILARITY_THRESHOLD } from "@/lib/rag/config";

const MISTRAL_API_KEY = process.env.MISTRAL_API_KEY;
const MISTRAL_AI_AGENT_ID = process.env.MISTRAL_AI_AGENT_ID;

const client = new Mistral({ apiKey: MISTRAL_API_KEY });

interface ChatMessage {
  role: "user" | "assistant";
  content: string;
  image?: string;
  images?: string[];
}

interface ChatRequest {
  messages: ChatMessage[];
  mode: "chat" | "image" | "search" | "code";
  enable_search: boolean;
  enable_code: boolean;
  image?: string;
  images?: string[];
  course_code?: string;
  level?: string;
}

/**
 * Search study material embeddings for context relevant to the user's question.
 * Returns a system prompt with the context, or null if no relevant chunks found.
 */
async function getRAGContext(
  question: string,
  courseCode?: string,
  level?: string
): Promise<string | null> {
  // üî¥ TEMPORARILY DISABLED BY USER REQUEST (TOKENS SAVING)
  console.log(`[RAG] üö´ RAG is temporarily disabled in chat route.`);
  return null;

  try {
    console.log(`[RAG] üîç Querying embeddings for: "${question.substring(0, 100)}..."`);
    const queryEmbedding = await embedText(question);
    const supabase = createAdminClient();

    console.log(`[RAG] üîç RPC Match Embeddings - Threshold: ${SIMILARITY_THRESHOLD}, Count: ${TOP_K}, Course: ${courseCode}, Level: ${level}`);
    
    // NOTE: Some PGVector implementations expect query_embedding as a raw array, not stringified.
    // We pass it as-is (array) which Supabase-JS handles.
    const { data, error } = await supabase.rpc("match_embeddings", {
      query_embedding: queryEmbedding, 
      match_threshold: SIMILARITY_THRESHOLD,
      match_count: TOP_K,
      filter_course_code: courseCode || null,
      filter_level: level || null,
    });
    
    // üåç Fallback: If no course-specific materials, search across the entire "RAG Bucket"
    if (!error && (!data || data.length === 0) && courseCode) {
      console.log(`[RAG] üåç Course search returned nothing. Retrying Global...`);
      const { data: globalData, error: globalError } = await supabase.rpc("match_embeddings", {
        query_embedding: queryEmbedding,
        match_threshold: SIMILARITY_THRESHOLD,
        match_count: TOP_K,
        filter_course_code: null,
        filter_level: null,
      });

      if (!globalError && globalData && globalData.length > 0) {
        console.log(`[RAG] ‚úÖ Success! Found ${globalData.length} materials in Global scope.`);
        return formatRAGPrompt(globalData);
      }
    }

    if (error) {
      console.error("[RAG] ‚ùå RPC Error:", error);
      return null;
    }

    if (!data || data.length === 0) {
      console.log("[RAG] ‚ö†Ô∏è No matching study materials found in ANY scope.");
      return null;
    }

    console.log(`[RAG] ‚úÖ Found ${data.length} relevant chunks:`);
    return formatRAGPrompt(data);
  } catch (err) {
    console.error("[RAG] ‚ùå Context retrieval failed:", err);
    return null;
  }
}

/**
 * Helper to format retrieval data into a system prompt.
 */
function formatRAGPrompt(data: any[]): string {
  const contextBlocks = data
    .map(
      (chunk: any, i: number) =>
        `--- Source ${i + 1} (${chunk.file_path}, relevance: ${(chunk.similarity * 100).toFixed(1)}%) ---\n${chunk.content}`
    )
    .join("\n\n");

  return `RELEVANT STUDY MATERIALS FOUND:
${contextBlocks}

INSTRUCTIONS FOR USING STUDY MATERIALS:
1. START YOUR RESPONSE by acknowledging the materials found, but DO NOT show raw technical file paths (e.g., avoid "pdf/12345.pdf"). Instead, use descriptive terms if possible or just refer to them as "uploaded study materials".
2. Use the provided study materials to answer the student's question accurately.
3. If the study materials don't cover the topic, answer from your general knowledge or search tools, but clarify what is and isn't from the uploaded materials.
4. Format responses with markdown for readability.`;
}

export async function POST(request: NextRequest) {
  try {
    if (!MISTRAL_API_KEY) {
      return NextResponse.json(
        { error: "Mistral API key not configured" },
        { status: 500 }
      );
    }

    const body: ChatRequest = await request.json();
    const { messages, mode, enable_search, images, course_code, level } = body;

    // Check if we have any images in the request or history
    const hasImages = (images && images.length > 0) || 
                      body.image || 
                      messages.some(m => m.image || (m as any).images?.length);

    // Convert messages to Mistral content format
    const mistralMessages: any[] = messages.map((msg, i) => {
      // If message has images, we use the vision content array format
      const msgImages = (msg as any).images || (msg.image ? [msg.image] : []);
      
      if (msgImages.length > 0) {
        return {
          role: msg.role,
          content: [
            { type: "text", text: msg.content || "Analyze this image." },
            ...msgImages.map((url: string) => ({
              type: "image_url",
              imageUrl: { url }
            }))
          ]
        };
      }
      
      // Text only
      return {
        role: msg.role,
        content: msg.content
      };
    });

    // üéì RAG: Search study material embeddings for context relevant to the user's question.
    if (messages.length > 0) {
      const lastUserMessage = messages.filter(m => m.role === "user").pop();
      if (lastUserMessage) {
        console.log(`[API] üïµÔ∏è Attempting RAG context retrieval...`);
        
        // Use a timeout to prevent RAG hanging the entire request
        const ragPromise = getRAGContext(lastUserMessage.content, course_code, level);
        const timeoutPromise = new Promise<null>((resolve) => 
          setTimeout(() => {
            console.warn("[API] ‚è±Ô∏è RAG retrieval timed out after 12s. Falling back to base AI.");
            resolve(null);
          }, 12000) // Increased from 6s: allows more time for cold DB starts and embedding calls
        );

        const ragContext = await Promise.race([ragPromise, timeoutPromise]);

        if (ragContext) {
          // Prepend as system message so the AI has study material context
          mistralMessages.unshift({
            role: "system",
            content: ragContext,
          });
        } else {
          // üí° FALLBACK: Inform the AI that no local context was found so it answers normally
          mistralMessages.unshift({
            role: "system",
            content: "Note: No specific study materials were found in the database for this query. Please answer based on your general knowledge or available web search tools.",
          });
        }
      }
    }

    if (mode === "search" || enable_search) {
      mistralMessages.unshift({
        role: "system",
        content: `SEARCH MODE ACTIVE. 
CRITICAL:
1. Provide the SEARCH RESULTS immediately in clean markdown. 
2. Use lists, bold text, and headers to present the data clearly.
3. If specific links or sources are found, include them.
4. Synthesize a brief final summary after the results.
5. NEVER output technical code/JSON or label segments like "web_search".`,
      });
    }

    // üöÄ LOGIC FOR AGENT
    // We strictly use the Agent ID from env, which handles both text and vision content.
    if (!MISTRAL_AI_AGENT_ID) {
      return NextResponse.json(
        { error: "Mistral AI Agent ID not configured" },
        { status: 500 }
      );
    }

    const shouldUseWebSearch = enable_search || mode === "search";
    console.log(`[API] AI Request - Mode: ${mode}, Has Images: ${hasImages}, WebSearch: ${shouldUseWebSearch}`);
    
    // üõ°Ô∏è SECURITY: Validate and filter messages before sending to API
    const finalMessages = validateMessages(mistralMessages);

    try {
      // ‚úÖ Standard Agent Logic (Mistral Agents handle tool/search execution automatically)
      const response = await client.agents.stream({
        agentId: MISTRAL_AI_AGENT_ID,
        messages: finalMessages,
        maxTokens: 2048, // Increase token limit for longer explanations
      });
      return streamResponse(response, mode, shouldUseWebSearch);
    } catch (apiError: any) {
      console.error("[API] ‚ùå Mistral failure:", apiError);
      return NextResponse.json(
        { error: `Mistral API Error: ${apiError.message}` },
        { status: 500 }
      );
    }
  } catch (error: any) {
    console.error("Total AI API Failure:", error);
    return NextResponse.json(
      { error: error.message || "Internal server error" },
      { status: 500 }
    );
  }
}

/**
 * Ensures all messages (especially assistant ones) are valid for Mistral API.
 * Mistral requires assistant messages to have EITHER content OR tool_calls.
 */
function validateMessages(messages: any[]): any[] {
  return messages.filter((msg, index) => {
    if (msg.role !== "assistant") return true;

    const hasContent = (msg.content && typeof msg.content === "string" && msg.content.trim().length > 0) || 
                       (Array.isArray(msg.content) && msg.content.length > 0);
    const hasToolCalls = (msg.tool_calls && Array.isArray(msg.tool_calls) && msg.tool_calls.length > 0) ||
                         (msg.toolCalls && Array.isArray(msg.toolCalls) && msg.toolCalls.length > 0);

    if (!hasContent && !hasToolCalls) {
      console.warn(`[API] üßπ Removing invalid assistant message at index ${index}: No content and no tool_calls.`);
      return false;
    }

    return true;
  });
}

/**
 * Helper to convert Mistral SDK stream to Next.js NextResponse
 */
async function streamResponse(response: any, mode: string, isSearch: boolean = false) {
  const encoder = new TextEncoder();
  
  const stream = new ReadableStream({
    async start(controller) {
      const STREAM_TIMEOUT = 120000; // 2 minutes max for a single stream
      const streamStart = Date.now();
      
      try {
        let hasEmittedContent = false;
        let lastChar = '';
        let repeatCount = 0;

        // üåê Connection keep-alive: Send an invisible pulse to prevent timeout during search
        if (isSearch) {
             controller.enqueue(encoder.encode(`data: ${JSON.stringify({
               choices: [{ delta: { content: "" } }] 
             })}\n\n`));
        }

        let chunkCount = 0;
        for await (const chunk of response) {
          // Check for stream timeout
          if (Date.now() - streamStart > STREAM_TIMEOUT) {
            console.error(`[API] ‚è±Ô∏è Stream timed out after ${STREAM_TIMEOUT}ms`);
            controller.enqueue(encoder.encode(`data: ${JSON.stringify({ error: "Stream timed out" })}\n\n`));
            break;
          }

          chunkCount++;
          const data = (chunk as any).data || chunk;
          const choice = data.choices?.[0];
          
          let content = "";
          const rawContent = choice?.delta?.content;
          
          // Debug log first few chunks
          if (chunkCount <= 5) {
            console.log(`[API] üß© Chunk ${chunkCount} raw content piece: "${typeof rawContent === 'string' ? rawContent.substring(0, 20) : 'complex'}"`);
          }
          
          // 1. Robust Content Extraction (Handles strings and multi-part content items)
          if (typeof rawContent === "string") {
            content = rawContent;
          } else if (Array.isArray(rawContent)) {
            // Handle array of content items (multipart)
            content = rawContent
              .map(part => (typeof part === 'string' ? part : (part as any).text || ""))
              .join("");
          } else if (rawContent && typeof rawContent === "object") {
            content = (rawContent as any).text || "";
          }
          
          if (content) {
            // 2. Surgical Filtering for Technical Debris
            const trimmed = content.trim();
            const isPureNoise = /^(\s*web_search\s*$|^thought\s*$|^\s*\{"query"|^\s*\[\s*\{"query")/i.test(trimmed);
            if (isPureNoise && trimmed.length < 50) {
              console.log(`[API] üßπ Filtered internal noise: "${content.substring(0, 50)}"`);
              continue; 
            }

            // 3. Repetitive Character Guard
            if (content === lastChar && content.length === 1 && !/[a-zA-Z0-9]/.test(content)) {
              repeatCount++;
              if (repeatCount > 10) continue; // Trapping dots/loops
            } else {
              lastChar = content.length === 1 ? content : '';
              repeatCount = 0;
            }

            hasEmittedContent = true;
            controller.enqueue(encoder.encode(`data: ${JSON.stringify({
              choices: [{ delta: { content } }]
            })}\n\n`));
          }

          // Handle tool calls privately
          const toolCalls = choice?.delta?.tool_calls || choice?.delta?.toolCalls || 
                          choice?.message?.tool_calls || choice?.message?.toolCalls;
          
          if (data.choices?.[0]?.finish_reason) {
            console.log(`[API] üèÅ Stream finished at chunk ${chunkCount}. Reason: ${data.choices[0].finish_reason}`);
          }

          if (toolCalls && toolCalls.length > 0) {
            console.log(`[API] üîß Tool call detected in chunk ${chunkCount}. Pulsing connection...`);
            // Always pulse on tool calls to keep connection alive
            controller.enqueue(encoder.encode(`data: ${JSON.stringify({
              choices: [{ delta: { content: "" } }]
            })}\n\n`));
          }
        }
        console.log(`[API] ‚úÖ Stream complete. Total chunks emitted: ${chunkCount}`);
        controller.enqueue(encoder.encode("data: [DONE]\n\n"));
      } catch (err) {
        controller.error(err);
      } finally {
        controller.close();
      }
    },
  });

  return new NextResponse(stream, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      "Connection": "keep-alive",
    },
  });
}
